{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a5d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb989699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports + config\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\"]\n",
    "\n",
    "# Market files: try your original path first; fallback to /mnt/data (project environment)\n",
    "MARKET_DIR_PRIMARY = \"data/raw/market\"\n",
    "MARKET_DIR_FALLBACK = \"/mnt/data\"\n",
    "\n",
    "# Macro / sentiment files (adjust if needed)\n",
    "PPI_FILE  = \"PPI_hourly.csv\"\n",
    "CPI_FILE  = \"CPI_hourly.csv\"\n",
    "FOMC_FILE = \"FOMC_rate_hourly.csv\"\n",
    "NFP_FILE  = \"NFP_hourly.csv\"\n",
    "GDP_FILE  = \"GDP_hourly.csv\"\n",
    "SENT_FILE = \"news_sentiment_hourly.csv\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8100b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper functions\n",
    "\n",
    "def _find_market_file(ticker: str) -> str:\n",
    "    p1 = os.path.join(MARKET_DIR_PRIMARY, f\"{ticker}_1h.csv\")\n",
    "    p2 = os.path.join(MARKET_DIR_FALLBACK, f\"{ticker}_1h.csv\")\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    if os.path.exists(p2):\n",
    "        return p2\n",
    "    raise FileNotFoundError(f\"Could not find market file for {ticker} in {p1} or {p2}\")\n",
    "\n",
    "def _read_market_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tries to read yfinance-style CSVs that sometimes include 3 metadata lines.\n",
    "    Falls back to a normal read if parsing fails.\n",
    "    \"\"\"\n",
    "    # Attempt 1: your known format (skip first 3 lines)\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        skiprows=3,\n",
    "        names=[\"Datetime\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "    )\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], utc=True, errors=\"coerce\")\n",
    "    if df[\"Datetime\"].isna().mean() > 0.20:\n",
    "        # Attempt 2: fallback (maybe file already has headers)\n",
    "        df = pd.read_csv(path)\n",
    "        # Try common column name variants\n",
    "        dt_col = \"Datetime\" if \"Datetime\" in df.columns else (\"Date\" if \"Date\" in df.columns else None)\n",
    "        if dt_col is None:\n",
    "            raise ValueError(f\"Could not find Datetime/Date column in {path}. Columns: {df.columns.tolist()}\")\n",
    "        df = df.rename(columns={dt_col: \"Datetime\"})\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        needed = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "        missing = [c for c in needed if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns {missing} in {path}. Columns: {df.columns.tolist()}\")\n",
    "\n",
    "        df = df[[\"Datetime\"] + needed]\n",
    "\n",
    "    # Clean\n",
    "    df = df.dropna(subset=[\"Datetime\"]).copy()\n",
    "    df = df.sort_values(\"Datetime\")\n",
    "    # Drop duplicate timestamps (keep last)\n",
    "    df = df.drop_duplicates(subset=[\"Datetime\"], keep=\"last\")\n",
    "\n",
    "    # Force numeric\n",
    "    for c in [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Close\", \"Volume\"]).copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def _minute_profile(dt_series: pd.Series) -> pd.Series:\n",
    "    return dt_series.dt.minute.value_counts(dropna=False).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaedf823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 24458\n",
      "Per-ticker row counts:\n",
      "ticker\n",
      "AAPL     3494\n",
      "AMZN     3494\n",
      "GOOGL    3494\n",
      "META     3494\n",
      "MSFT     3494\n",
      "NVDA     3494\n",
      "TSLA     3494\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Market timestamp minute profile (should be stable, often all 30):\n",
      "Datetime\n",
      "30    24458\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-06 14:30:00+00:00</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>194.759995</td>\n",
       "      <td>192.205002</td>\n",
       "      <td>194.449997</td>\n",
       "      <td>11260893</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-06 15:30:00+00:00</td>\n",
       "      <td>193.095001</td>\n",
       "      <td>193.339996</td>\n",
       "      <td>192.360107</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>4374474</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06 16:30:00+00:00</td>\n",
       "      <td>192.830002</td>\n",
       "      <td>193.130005</td>\n",
       "      <td>192.470001</td>\n",
       "      <td>193.100006</td>\n",
       "      <td>3252326</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-06 17:30:00+00:00</td>\n",
       "      <td>192.905899</td>\n",
       "      <td>192.979996</td>\n",
       "      <td>192.369995</td>\n",
       "      <td>192.839996</td>\n",
       "      <td>3389634</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-06 18:30:00+00:00</td>\n",
       "      <td>192.779999</td>\n",
       "      <td>193.235001</td>\n",
       "      <td>192.740005</td>\n",
       "      <td>192.910004</td>\n",
       "      <td>2713794</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime       Close        High         Low        Open    Volume ticker\n",
       "0 2023-12-06 14:30:00+00:00  192.419998  194.759995  192.205002  194.449997  11260893   AAPL\n",
       "1 2023-12-06 15:30:00+00:00  193.095001  193.339996  192.360107  192.419998   4374474   AAPL\n",
       "2 2023-12-06 16:30:00+00:00  192.830002  193.130005  192.470001  193.100006   3252326   AAPL\n",
       "3 2023-12-06 17:30:00+00:00  192.905899  192.979996  192.369995  192.839996   3389634   AAPL\n",
       "4 2023-12-06 18:30:00+00:00  192.779999  193.235001  192.740005  192.910004   2713794   AAPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Load all tickers (NO reindex / NO ffill)\n",
    "\n",
    "market_dfs = []\n",
    "for t in TICKERS:\n",
    "    fpath = _find_market_file(t)\n",
    "    dft = _read_market_csv(fpath)\n",
    "    dft[\"ticker\"] = t\n",
    "    market_dfs.append(dft)\n",
    "\n",
    "prices_all = pd.concat(market_dfs, ignore_index=True)\n",
    "prices_all = prices_all.sort_values([\"ticker\", \"Datetime\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded rows:\", len(prices_all))\n",
    "print(\"Per-ticker row counts:\")\n",
    "print(prices_all[\"ticker\"].value_counts())\n",
    "print(\"\\nMarket timestamp minute profile (should be stable, often all 30):\")\n",
    "print(_minute_profile(prices_all[\"Datetime\"]))\n",
    "prices_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641f664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap distribution (hours) - per ticker (top few values):\n",
      "\n",
      "AAPL:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MSFT:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "GOOGL:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMZN:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NVDA:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "META:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TSLA:\n",
      "dt_diff_hours\n",
      "1.0     2992\n",
      "18.0     389\n",
      "66.0      85\n",
      "90.0      12\n",
      "42.0       6\n",
      "65.0       2\n",
      "46.0       2\n",
      "67.0       2\n",
      "70.0       2\n",
      "94.0       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Gap diagnostics (expect >1h gaps because we removed synthetic bars)\n",
    "\n",
    "tmp = prices_all.sort_values([\"ticker\", \"Datetime\"]).copy()\n",
    "tmp[\"dt_diff_hours\"] = tmp.groupby(\"ticker\")[\"Datetime\"].diff().dt.total_seconds() / 3600.0\n",
    "\n",
    "print(\"Gap distribution (hours) - per ticker (top few values):\")\n",
    "for t in TICKERS:\n",
    "    s = tmp.loc[tmp[\"ticker\"] == t, \"dt_diff_hours\"].dropna()\n",
    "    print(f\"\\n{t}:\")\n",
    "    print(s.value_counts().head(10))\n",
    "\n",
    "# If you see a massive number of exactly 1.0 gaps AND many 18h gaps, that's normal for intraday-only data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36dacc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market minute mode: 30\n",
      "Dropped 0 rows due to macro NaNs (early prefix).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>PPI_YoY</th>\n",
       "      <th>CPI_YoY</th>\n",
       "      <th>CPI_MoM</th>\n",
       "      <th>Fed_Funds_Rate</th>\n",
       "      <th>NonFarm_Payrolls_Change</th>\n",
       "      <th>GDP_Growth_QoQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-06 14:30:00+00:00</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>194.759995</td>\n",
       "      <td>192.205002</td>\n",
       "      <td>194.449997</td>\n",
       "      <td>11260893</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-06 15:30:00+00:00</td>\n",
       "      <td>193.095001</td>\n",
       "      <td>193.339996</td>\n",
       "      <td>192.360107</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>4374474</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06 16:30:00+00:00</td>\n",
       "      <td>192.830002</td>\n",
       "      <td>193.130005</td>\n",
       "      <td>192.470001</td>\n",
       "      <td>193.100006</td>\n",
       "      <td>3252326</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-06 17:30:00+00:00</td>\n",
       "      <td>192.905899</td>\n",
       "      <td>192.979996</td>\n",
       "      <td>192.369995</td>\n",
       "      <td>192.839996</td>\n",
       "      <td>3389634</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-06 18:30:00+00:00</td>\n",
       "      <td>192.779999</td>\n",
       "      <td>193.235001</td>\n",
       "      <td>192.740005</td>\n",
       "      <td>192.910004</td>\n",
       "      <td>2713794</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime       Close        High         Low        Open    Volume ticker   PPI_YoY   CPI_YoY   CPI_MoM  \\\n",
       "0 2023-12-06 14:30:00+00:00  192.419998  194.759995  192.205002  194.449997  11260893   AAPL  1.105605  3.246538  0.244648   \n",
       "1 2023-12-06 15:30:00+00:00  193.095001  193.339996  192.360107  192.419998   4374474   AAPL  1.105605  3.246538  0.244648   \n",
       "2 2023-12-06 16:30:00+00:00  192.830002  193.130005  192.470001  193.100006   3252326   AAPL  1.105605  3.246538  0.244648   \n",
       "3 2023-12-06 17:30:00+00:00  192.905899  192.979996  192.369995  192.839996   3389634   AAPL  1.105605  3.246538  0.244648   \n",
       "4 2023-12-06 18:30:00+00:00  192.779999  193.235001  192.740005  192.910004   2713794   AAPL  1.105605  3.246538  0.244648   \n",
       "\n",
       "   Fed_Funds_Rate  NonFarm_Payrolls_Change  GDP_Growth_QoQ  \n",
       "0             5.5                    141.0             4.9  \n",
       "1             5.5                    141.0             4.9  \n",
       "2             5.5                    141.0             4.9  \n",
       "3             5.5                    141.0             4.9  \n",
       "4             5.5                    141.0             4.9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Macro loader + merge helper\n",
    "\n",
    "def load_macro_csv(path: str, cols: list[str]) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Datetime\" not in df.columns:\n",
    "        raise ValueError(f\"{path}: no Datetime column. Columns={df.columns.tolist()}\")\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], utc=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Datetime\"]).sort_values(\"Datetime\")\n",
    "    keep = [\"Datetime\"] + [c for c in cols if c in df.columns]\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path}: missing columns {missing}. Columns={df.columns.tolist()}\")\n",
    "    return df[keep].copy()\n",
    "\n",
    "def align_macro_to_market_minutes(macro_df: pd.DataFrame, market_minutes: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If macro timestamps are HH:00 but market is HH:30 (or similar),\n",
    "    shift macro timestamps so they match market minute.\n",
    "    \"\"\"\n",
    "    macro_minutes = int(macro_df[\"Datetime\"].dt.minute.mode().iloc[0])\n",
    "    if macro_minutes == market_minutes:\n",
    "        return macro_df\n",
    "    # Example: macro at :00, market at :30 => shift +30 minutes\n",
    "    delta = (market_minutes - macro_minutes) % 60\n",
    "    macro_df = macro_df.copy()\n",
    "    macro_df[\"Datetime\"] = macro_df[\"Datetime\"] + pd.Timedelta(minutes=delta)\n",
    "    return macro_df\n",
    "\n",
    "market_minute_mode = int(prices_all[\"Datetime\"].dt.minute.mode().iloc[0])\n",
    "print(\"Market minute mode:\", market_minute_mode)\n",
    "\n",
    "# Load macros\n",
    "ppi  = load_macro_csv(PPI_FILE,  [\"PPI_YoY\"])\n",
    "cpi  = load_macro_csv(CPI_FILE,  [\"CPI_YoY\", \"CPI_MoM\"])\n",
    "fomc = load_macro_csv(FOMC_FILE, [\"Fed_Funds_Rate\"])\n",
    "nfp  = load_macro_csv(NFP_FILE,  [\"NonFarm_Payrolls_Change\"])\n",
    "gdp  = load_macro_csv(GDP_FILE,  [\"GDP_Growth_QoQ\"])\n",
    "\n",
    "# Align macros to market minute if needed\n",
    "ppi  = align_macro_to_market_minutes(ppi,  market_minute_mode)\n",
    "cpi  = align_macro_to_market_minutes(cpi,  market_minute_mode)\n",
    "fomc = align_macro_to_market_minutes(fomc, market_minute_mode)\n",
    "nfp  = align_macro_to_market_minutes(nfp,  market_minute_mode)\n",
    "gdp  = align_macro_to_market_minutes(gdp,  market_minute_mode)\n",
    "\n",
    "# Merge (left join on Datetime)\n",
    "prices_all = prices_all.merge(ppi,  on=\"Datetime\", how=\"left\")\n",
    "prices_all = prices_all.merge(cpi,  on=\"Datetime\", how=\"left\")\n",
    "prices_all = prices_all.merge(fomc, on=\"Datetime\", how=\"left\")\n",
    "prices_all = prices_all.merge(nfp,  on=\"Datetime\", how=\"left\")\n",
    "prices_all = prices_all.merge(gdp,  on=\"Datetime\", how=\"left\")\n",
    "\n",
    "# Forward-fill macros by time per ticker (no bfill)\n",
    "macro_cols = [\"PPI_YoY\", \"CPI_YoY\", \"CPI_MoM\", \"Fed_Funds_Rate\", \"NonFarm_Payrolls_Change\", \"GDP_Growth_QoQ\"]\n",
    "prices_all = prices_all.sort_values([\"ticker\", \"Datetime\"])\n",
    "prices_all[macro_cols] = prices_all.groupby(\"ticker\")[macro_cols].ffill()\n",
    "\n",
    "# Drop any remaining NaNs (early prefix) for macro columns\n",
    "before = len(prices_all)\n",
    "prices_all = prices_all.dropna(subset=macro_cols).reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(prices_all)} rows due to macro NaNs (early prefix).\")\n",
    "prices_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa957e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment minute profile (before align):\n",
      "Datetime\n",
      "0    180607\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment minute profile (after align):\n",
      "Datetime\n",
      "30    180607\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rows with news_count>0 after merge: 1865\n",
      "                     Datetime ticker  news_count\n",
      "0   2023-12-06 14:30:00+00:00   AAPL           1\n",
      "7   2023-12-07 14:30:00+00:00   AAPL           1\n",
      "64  2023-12-19 15:30:00+00:00   AAPL           1\n",
      "239 2024-01-26 15:30:00+00:00   AAPL           1\n",
      "254 2024-01-30 16:30:00+00:00   AAPL           1\n",
      "272 2024-02-01 20:30:00+00:00   AAPL           1\n",
      "292 2024-02-06 19:30:00+00:00   AAPL           1\n",
      "330 2024-02-14 15:30:00+00:00   AAPL           1\n",
      "400 2024-02-29 15:30:00+00:00   AAPL           1\n",
      "448 2024-03-11 13:30:00+00:00   AAPL           1\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Sentiment load + alignment that will not double-shift\n",
    "\n",
    "sent = pd.read_csv(SENT_FILE)\n",
    "if \"Datetime\" not in sent.columns or \"ticker\" not in sent.columns or \"news_count\" not in sent.columns:\n",
    "    raise ValueError(f\"{SENT_FILE} must include at least Datetime, ticker, news_count. Columns={sent.columns.tolist()}\")\n",
    "\n",
    "sent[\"Datetime\"] = pd.to_datetime(sent[\"Datetime\"], utc=True, errors=\"coerce\")\n",
    "sent = sent.dropna(subset=[\"Datetime\"]).sort_values([\"ticker\", \"Datetime\"]).copy()\n",
    "\n",
    "print(\"Sentiment minute profile (before align):\")\n",
    "print(_minute_profile(sent[\"Datetime\"]))\n",
    "\n",
    "def align_sentiment_to_market(sent_df: pd.DataFrame, market_minute: int) -> pd.DataFrame:\n",
    "    sent_df = sent_df.copy()\n",
    "    sent_minute_mode = int(sent_df[\"Datetime\"].dt.minute.mode().iloc[0])\n",
    "\n",
    "    # If already matches market minute, do nothing\n",
    "    if sent_minute_mode == market_minute:\n",
    "        return sent_df\n",
    "\n",
    "    # If sentiment is HH:00 and market is HH:30, shift +30; otherwise shift to match\n",
    "    delta = (market_minute - sent_minute_mode) % 60\n",
    "    sent_df[\"Datetime\"] = sent_df[\"Datetime\"] + pd.Timedelta(minutes=delta)\n",
    "    return sent_df\n",
    "\n",
    "sent = align_sentiment_to_market(sent, market_minute_mode)\n",
    "\n",
    "print(\"\\nSentiment minute profile (after align):\")\n",
    "print(_minute_profile(sent[\"Datetime\"]))\n",
    "\n",
    "# Create sentiment features (same as your logic)\n",
    "sent[\"has_news\"] = (sent[\"news_count\"] > 0).astype(int)\n",
    "\n",
    "# If these columns exist in your file, we’ll use them; else we create safe zeros\n",
    "for base_col in [\"overall_sentiment_mean\", \"ticker_sentiment_mean\", \"ticker_relevance_mean\"]:\n",
    "    if base_col not in sent.columns:\n",
    "        sent[base_col] = np.nan\n",
    "\n",
    "sent[\"overall_sentiment_ffill\"] = sent.groupby(\"ticker\")[\"overall_sentiment_mean\"].ffill().fillna(0.0)\n",
    "sent[\"ticker_sentiment_ffill\"]  = sent.groupby(\"ticker\")[\"ticker_sentiment_mean\"].ffill().fillna(0.0)\n",
    "sent[\"ticker_relevance_ffill\"]  = sent.groupby(\"ticker\")[\"ticker_relevance_mean\"].ffill().fillna(0.0)\n",
    "\n",
    "sent_merge = sent[[\n",
    "    \"Datetime\", \"ticker\",\n",
    "    \"news_count\", \"has_news\",\n",
    "    \"overall_sentiment_ffill\", \"ticker_sentiment_ffill\", \"ticker_relevance_ffill\"\n",
    "]].copy()\n",
    "\n",
    "prices_all = prices_all.merge(sent_merge, on=[\"Datetime\", \"ticker\"], how=\"left\")\n",
    "\n",
    "# Fill missing sentiment with zeros\n",
    "fill0 = [\"news_count\", \"has_news\", \"overall_sentiment_ffill\", \"ticker_sentiment_ffill\", \"ticker_relevance_ffill\"]\n",
    "prices_all[fill0] = prices_all[fill0].fillna(0)\n",
    "\n",
    "# Proof that join works (should be >0 if your sentiment file actually contains news)\n",
    "probe = prices_all.loc[prices_all[\"news_count\"] > 0, [\"Datetime\", \"ticker\", \"news_count\"]]\n",
    "print(\"\\nRows with news_count>0 after merge:\", len(probe))\n",
    "print(probe.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad0ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.42673153978248424\n",
      "count    10437.0\n",
      "mean         4.0\n",
      "std          0.0\n",
      "min          4.0\n",
      "50%          4.0\n",
      "90%          4.0\n",
      "95%          4.0\n",
      "99%          4.0\n",
      "max          4.0\n",
      "Name: matched_delta_hours, dtype: float64\n",
      "Dropped 14021 rows without a valid +4h target.\n"
     ]
    }
   ],
   "source": [
    "prices_all = prices_all.drop(columns=[\n",
    "    \"target_log_return_tplus4h\",\n",
    "    \"target_log_return_tplus4bars\",\n",
    "    \"target_time\",\n",
    "    \"match_time\",\n",
    "    \"match_close\",\n",
    "], errors=\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "HORIZON = pd.Timedelta(hours=4)\n",
    "\n",
    "# Tolerance = how late you're willing to accept the first bar AFTER the target_time.\n",
    "# For 1h bars, 60–90 minutes is typical. 2h is often too permissive (can drift too far).\n",
    "TOL = pd.Timedelta(minutes=90)\n",
    "\n",
    "def build_time_target_asof(prices: pd.DataFrame,\n",
    "                           horizon: pd.Timedelta,\n",
    "                           tolerance: pd.Timedelta,\n",
    "                           keep_debug_cols: bool = True) -> pd.DataFrame:\n",
    "    prices = prices.sort_values([\"ticker\", \"Datetime\"]).reset_index(drop=True).copy()\n",
    "    prices[\"target_time\"] = prices[\"Datetime\"] + horizon\n",
    "\n",
    "    out = []\n",
    "    for t, g in prices.groupby(\"ticker\", sort=False):\n",
    "        g = g.sort_values(\"Datetime\").copy()\n",
    "\n",
    "        right = g[[\"Datetime\", \"Close\"]].rename(\n",
    "            columns={\"Datetime\": \"match_time\", \"Close\": \"match_close\"}\n",
    "        )\n",
    "\n",
    "        left = g[[\"Datetime\", \"Close\", \"target_time\"]].copy()\n",
    "\n",
    "        m = pd.merge_asof(\n",
    "            left.sort_values(\"target_time\"),\n",
    "            right.sort_values(\"match_time\"),\n",
    "            left_on=\"target_time\",\n",
    "            right_on=\"match_time\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=tolerance,\n",
    "        )\n",
    "\n",
    "        m[\"ticker\"] = t\n",
    "        out.append(m)\n",
    "\n",
    "    df2 = pd.concat(out, ignore_index=True)\n",
    "\n",
    "    # target: log return from now -> matched future close\n",
    "    df2[\"target_log_return_tplus4h\"] = np.log(df2[\"match_close\"] / df2[\"Close\"])\n",
    "    df2[\"matched_delta_hours\"] = (df2[\"match_time\"] - df2[\"Datetime\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "    # Diagnostics\n",
    "    hit_rate = df2[\"match_close\"].notna().mean()\n",
    "    print(\"Hit rate:\", hit_rate)\n",
    "    print(df2[\"matched_delta_hours\"].describe(percentiles=[0.5, 0.9, 0.95, 0.99]))\n",
    "\n",
    "    # Merge back into prices (cleanly, no _x/_y)\n",
    "    keep_cols = [\"ticker\", \"Datetime\", \"target_log_return_tplus4h\"]\n",
    "    if keep_debug_cols:\n",
    "        keep_cols += [\"match_time\", \"matched_delta_hours\"]\n",
    "\n",
    "    prices = prices.merge(df2[keep_cols], on=[\"ticker\", \"Datetime\"], how=\"left\")\n",
    "\n",
    "    # Drop rows without targets (or keep them if you prefer)\n",
    "    before = len(prices)\n",
    "    prices = prices.dropna(subset=[\"target_log_return_tplus4h\"]).reset_index(drop=True)\n",
    "    print(f\"Dropped {before - len(prices)} rows without a valid +4h target.\")\n",
    "\n",
    "    # cleanup\n",
    "    prices = prices.drop(columns=[\"target_time\"], errors=\"ignore\")\n",
    "    return prices\n",
    "\n",
    "prices_all = build_time_target_asof(prices_all, HORIZON, TOL, keep_debug_cols=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faea7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 7 rows due to first return per ticker.\n",
      "count    10430.000000\n",
      "mean         0.000453\n",
      "std          0.014290\n",
      "min         -0.152306\n",
      "25%         -0.003966\n",
      "50%          0.000230\n",
      "75%          0.004724\n",
      "max          0.180256\n",
      "Name: log_return_1h, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>PPI_YoY</th>\n",
       "      <th>CPI_YoY</th>\n",
       "      <th>CPI_MoM</th>\n",
       "      <th>Fed_Funds_Rate</th>\n",
       "      <th>NonFarm_Payrolls_Change</th>\n",
       "      <th>GDP_Growth_QoQ</th>\n",
       "      <th>news_count</th>\n",
       "      <th>has_news</th>\n",
       "      <th>overall_sentiment_ffill</th>\n",
       "      <th>ticker_sentiment_ffill</th>\n",
       "      <th>ticker_relevance_ffill</th>\n",
       "      <th>target_log_return_tplus4h</th>\n",
       "      <th>match_time</th>\n",
       "      <th>matched_delta_hours</th>\n",
       "      <th>log_return_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-06 15:30:00+00:00</td>\n",
       "      <td>193.095001</td>\n",
       "      <td>193.339996</td>\n",
       "      <td>192.360107</td>\n",
       "      <td>192.419998</td>\n",
       "      <td>4374474</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.624819</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>2023-12-06 19:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-06 16:30:00+00:00</td>\n",
       "      <td>192.830002</td>\n",
       "      <td>193.130005</td>\n",
       "      <td>192.470001</td>\n",
       "      <td>193.100006</td>\n",
       "      <td>3252326</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.624819</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>2023-12-06 20:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-07 14:30:00+00:00</td>\n",
       "      <td>194.725006</td>\n",
       "      <td>194.919998</td>\n",
       "      <td>193.589996</td>\n",
       "      <td>193.630005</td>\n",
       "      <td>11958910</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.582547</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>2023-12-07 18:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-07 15:30:00+00:00</td>\n",
       "      <td>194.300003</td>\n",
       "      <td>194.979996</td>\n",
       "      <td>194.020004</td>\n",
       "      <td>194.725006</td>\n",
       "      <td>5216520</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.582547</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>2023-12-07 19:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-07 16:30:00+00:00</td>\n",
       "      <td>194.940002</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>194.214996</td>\n",
       "      <td>194.289993</td>\n",
       "      <td>4611066</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.105605</td>\n",
       "      <td>3.246538</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.582547</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>2023-12-07 20:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.003288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime       Close        High         Low        Open    Volume ticker   PPI_YoY   CPI_YoY   CPI_MoM  \\\n",
       "0 2023-12-06 15:30:00+00:00  193.095001  193.339996  192.360107  192.419998   4374474   AAPL  1.105605  3.246538  0.244648   \n",
       "1 2023-12-06 16:30:00+00:00  192.830002  193.130005  192.470001  193.100006   3252326   AAPL  1.105605  3.246538  0.244648   \n",
       "2 2023-12-07 14:30:00+00:00  194.725006  194.919998  193.589996  193.630005  11958910   AAPL  1.105605  3.246538  0.244648   \n",
       "3 2023-12-07 15:30:00+00:00  194.300003  194.979996  194.020004  194.725006   5216520   AAPL  1.105605  3.246538  0.244648   \n",
       "4 2023-12-07 16:30:00+00:00  194.940002  195.000000  194.214996  194.289993   4611066   AAPL  1.105605  3.246538  0.244648   \n",
       "\n",
       "   Fed_Funds_Rate  NonFarm_Payrolls_Change  GDP_Growth_QoQ  news_count  has_news  overall_sentiment_ffill  ticker_sentiment_ffill  \\\n",
       "0             5.5                    141.0             4.9           0         0                    0.001                   0.001   \n",
       "1             5.5                    141.0             4.9           0         0                    0.001                   0.001   \n",
       "2             5.5                    141.0             4.9           1         1                    0.001                   0.001   \n",
       "3             5.5                    141.0             4.9           0         0                    0.001                   0.001   \n",
       "4             5.5                    141.0             4.9           0         0                    0.001                   0.001   \n",
       "\n",
       "   ticker_relevance_ffill  target_log_return_tplus4h                match_time  matched_delta_hours  log_return_1h  \n",
       "0                0.624819                  -0.003471 2023-12-06 19:30:00+00:00                  4.0       0.003502  \n",
       "1                0.624819                  -0.002700 2023-12-06 20:30:00+00:00                  4.0      -0.001373  \n",
       "2                0.582547                  -0.001310 2023-12-07 18:30:00+00:00                  4.0       0.009779  \n",
       "3                0.582547                  -0.000669 2023-12-07 19:30:00+00:00                  4.0      -0.002185  \n",
       "4                0.582547                  -0.003597 2023-12-07 20:30:00+00:00                  4.0       0.003288  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: 1-bar log return (per ticker)\n",
    "\n",
    "prices_all[\"log_return_1h\"] = prices_all.groupby(\"ticker\")[\"Close\"].transform(lambda x: np.log(x / x.shift(1)))\n",
    "\n",
    "before = len(prices_all)\n",
    "prices_all = prices_all.dropna(subset=[\"log_return_1h\"]).reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(prices_all)} rows due to first return per ticker.\")\n",
    "\n",
    "print(prices_all[\"log_return_1h\"].describe())\n",
    "prices_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d3ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 161 rows due to vol warmup (~24 bars per ticker).\n",
      "            vol_12h       vol_24h\n",
      "count  10269.000000  10269.000000\n",
      "mean       0.012006      0.012495\n",
      "std        0.007909      0.007099\n",
      "min        0.001742      0.002937\n",
      "25%        0.006639      0.007425\n",
      "50%        0.009706      0.010319\n",
      "75%        0.014626      0.015744\n",
      "max        0.054916      0.044410\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>PPI_YoY</th>\n",
       "      <th>CPI_YoY</th>\n",
       "      <th>CPI_MoM</th>\n",
       "      <th>Fed_Funds_Rate</th>\n",
       "      <th>NonFarm_Payrolls_Change</th>\n",
       "      <th>GDP_Growth_QoQ</th>\n",
       "      <th>news_count</th>\n",
       "      <th>has_news</th>\n",
       "      <th>overall_sentiment_ffill</th>\n",
       "      <th>ticker_sentiment_ffill</th>\n",
       "      <th>ticker_relevance_ffill</th>\n",
       "      <th>target_log_return_tplus4h</th>\n",
       "      <th>match_time</th>\n",
       "      <th>matched_delta_hours</th>\n",
       "      <th>log_return_1h</th>\n",
       "      <th>vol_12h</th>\n",
       "      <th>vol_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-18 14:30:00+00:00</td>\n",
       "      <td>195.365005</td>\n",
       "      <td>196.630005</td>\n",
       "      <td>194.410004</td>\n",
       "      <td>196.089996</td>\n",
       "      <td>16633548</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>3.139856</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>2023-12-18 18:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.012033</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.006696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-18 15:30:00+00:00</td>\n",
       "      <td>194.929993</td>\n",
       "      <td>195.524994</td>\n",
       "      <td>194.619995</td>\n",
       "      <td>195.360001</td>\n",
       "      <td>6011735</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>3.139856</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>2023-12-18 19:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.002229</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.006691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-18 16:30:00+00:00</td>\n",
       "      <td>195.250107</td>\n",
       "      <td>195.350006</td>\n",
       "      <td>194.695007</td>\n",
       "      <td>194.929993</td>\n",
       "      <td>4447711</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>3.139856</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>2023-12-18 20:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.006685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-19 14:30:00+00:00</td>\n",
       "      <td>196.539993</td>\n",
       "      <td>196.654999</td>\n",
       "      <td>195.889999</td>\n",
       "      <td>196.160004</td>\n",
       "      <td>9236022</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>3.139856</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>2023-12-19 18:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-19 15:30:00+00:00</td>\n",
       "      <td>196.600006</td>\n",
       "      <td>196.949997</td>\n",
       "      <td>196.277496</td>\n",
       "      <td>196.550003</td>\n",
       "      <td>4831194</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>3.139856</td>\n",
       "      <td>0.033478</td>\n",
       "      <td>5.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281733</td>\n",
       "      <td>0.311306</td>\n",
       "      <td>0.738393</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>2023-12-19 19:30:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>0.006500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime       Close        High         Low        Open    Volume ticker   PPI_YoY   CPI_YoY   CPI_MoM  \\\n",
       "0 2023-12-18 14:30:00+00:00  195.365005  196.630005  194.410004  196.089996  16633548   AAPL  0.839979  3.139856  0.033478   \n",
       "1 2023-12-18 15:30:00+00:00  194.929993  195.524994  194.619995  195.360001   6011735   AAPL  0.839979  3.139856  0.033478   \n",
       "2 2023-12-18 16:30:00+00:00  195.250107  195.350006  194.695007  194.929993   4447711   AAPL  0.839979  3.139856  0.033478   \n",
       "3 2023-12-19 14:30:00+00:00  196.539993  196.654999  195.889999  196.160004   9236022   AAPL  0.839979  3.139856  0.033478   \n",
       "4 2023-12-19 15:30:00+00:00  196.600006  196.949997  196.277496  196.550003   4831194   AAPL  0.839979  3.139856  0.033478   \n",
       "\n",
       "   Fed_Funds_Rate  NonFarm_Payrolls_Change  GDP_Growth_QoQ  news_count  has_news  overall_sentiment_ffill  ticker_sentiment_ffill  \\\n",
       "0             5.5                    141.0             4.9           0         0                 0.001000                0.001000   \n",
       "1             5.5                    141.0             4.9           0         0                 0.001000                0.001000   \n",
       "2             5.5                    141.0             4.9           0         0                 0.001000                0.001000   \n",
       "3             5.5                    141.0             4.9           0         0                 0.001000                0.001000   \n",
       "4             5.5                    141.0             4.9           1         1                 0.281733                0.311306   \n",
       "\n",
       "   ticker_relevance_ffill  target_log_return_tplus4h                match_time  matched_delta_hours  log_return_1h   vol_12h   vol_24h  \n",
       "0                0.983081                   0.004315 2023-12-18 18:30:00+00:00                  4.0      -0.012033  0.007615  0.006696  \n",
       "1                0.983081                   0.006494 2023-12-18 19:30:00+00:00                  4.0      -0.002229  0.007665  0.006691  \n",
       "2                0.983081                   0.003131 2023-12-18 20:30:00+00:00                  4.0       0.001641  0.007669  0.006685  \n",
       "3                0.983081                  -0.002394 2023-12-19 18:30:00+00:00                  4.0       0.006585  0.006410  0.006522  \n",
       "4                0.738393                  -0.000763 2023-12-19 19:30:00+00:00                  4.0       0.000305  0.006346  0.006500  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Rolling volatility on log returns (bars, not calendar hours)\n",
    "\n",
    "prices_all[\"vol_12h\"] = prices_all.groupby(\"ticker\")[\"log_return_1h\"].transform(\n",
    "    lambda x: x.rolling(window=12, min_periods=12).std()\n",
    ")\n",
    "prices_all[\"vol_24h\"] = prices_all.groupby(\"ticker\")[\"log_return_1h\"].transform(\n",
    "    lambda x: x.rolling(window=24, min_periods=24).std()\n",
    ")\n",
    "\n",
    "before = len(prices_all)\n",
    "prices_all = prices_all.dropna(subset=[\"vol_24h\"]).reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(prices_all)} rows due to vol warmup (~24 bars per ticker).\")\n",
    "\n",
    "print(prices_all[[\"vol_12h\", \"vol_24h\"]].describe())\n",
    "prices_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314860ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 161 rows due to volume z-score warmup (~24 bars per ticker).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_volume</th>\n",
       "      <th>vol_z_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10108.000000</td>\n",
       "      <td>10108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.554633</td>\n",
       "      <td>-0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.249378</td>\n",
       "      <td>1.012471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.635224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.781673</td>\n",
       "      <td>-0.826374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.440933</td>\n",
       "      <td>-0.117275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.310696</td>\n",
       "      <td>0.745112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.311836</td>\n",
       "      <td>3.675914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         log_volume     vol_z_24h\n",
       "count  10108.000000  10108.000000\n",
       "mean      15.554633     -0.012098\n",
       "std        1.249378      1.012471\n",
       "min        0.000000     -4.635224\n",
       "25%       14.781673     -0.826374\n",
       "50%       15.440933     -0.117275\n",
       "75%       16.310696      0.745112\n",
       "max       19.311836      3.675914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Volume features (no forward-fill of Volume anywhere)\n",
    "\n",
    "prices_all[\"log_volume\"] = np.log(prices_all[\"Volume\"].clip(lower=0) + 1)\n",
    "\n",
    "def rolling_zscore(x: pd.Series, window: int = 24) -> pd.Series:\n",
    "    mu = x.rolling(window, min_periods=window).mean()\n",
    "    sd = x.rolling(window, min_periods=window).std()\n",
    "    return (x - mu) / sd\n",
    "\n",
    "prices_all[\"vol_z_24h\"] = prices_all.groupby(\"ticker\")[\"log_volume\"].transform(lambda x: rolling_zscore(x, 24))\n",
    "\n",
    "before = len(prices_all)\n",
    "prices_all = prices_all.dropna(subset=[\"vol_z_24h\"]).reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(prices_all)} rows due to volume z-score warmup (~24 bars per ticker).\")\n",
    "\n",
    "prices_all[[\"log_volume\", \"vol_z_24h\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7448a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TARGET_COL = target_log_return_tplus4h\n",
      "Total features: 16\n",
      "['log_return_1h', 'vol_12h', 'vol_24h', 'log_volume', 'vol_z_24h', 'news_count', 'has_news', 'ticker_sentiment_ffill', 'overall_sentiment_ffill', 'ticker_relevance_ffill', 'CPI_YoY', 'CPI_MoM', 'PPI_YoY', 'GDP_Growth_QoQ', 'Fed_Funds_Rate', 'NonFarm_Payrolls_Change']\n",
      "\n",
      "Top NaN counts (should all be 0):\n",
      "log_return_1h              0\n",
      "vol_12h                    0\n",
      "vol_24h                    0\n",
      "log_volume                 0\n",
      "vol_z_24h                  0\n",
      "news_count                 0\n",
      "has_news                   0\n",
      "ticker_sentiment_ffill     0\n",
      "overall_sentiment_ffill    0\n",
      "ticker_relevance_ffill     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Feature sets\n",
    "\n",
    "RETURN_COLS = [\"log_return_1h\"]\n",
    "\n",
    "VOL_COLS = [\"vol_12h\", \"vol_24h\"]\n",
    "\n",
    "VOLUME_COLS = [\"log_volume\", \"vol_z_24h\"]\n",
    "\n",
    "SENTIMENT_COLS = [\n",
    "    \"news_count\",\n",
    "    \"has_news\",\n",
    "    \"ticker_sentiment_ffill\",\n",
    "    \"overall_sentiment_ffill\",\n",
    "    \"ticker_relevance_ffill\"\n",
    "]\n",
    "\n",
    "MACRO_COLS = [\n",
    "    \"CPI_YoY\", \"CPI_MoM\",\n",
    "    \"PPI_YoY\",\n",
    "    \"GDP_Growth_QoQ\",\n",
    "    \"Fed_Funds_Rate\",\n",
    "    \"NonFarm_Payrolls_Change\"\n",
    "]\n",
    "\n",
    "# Use the truthful target name for Option 1\n",
    "# --- Target column resolver (prevents KeyError if you change target definition)\n",
    "CANDIDATE_TARGETS = [\n",
    "    \"target_log_return_tplus4h\",       # Option A1 (time-based)\n",
    "    \"target_log_return_tplus4bars\",    # old bar-based target\n",
    "]\n",
    "\n",
    "found = [c for c in CANDIDATE_TARGETS if c in prices_all.columns]\n",
    "if not found:\n",
    "    raise KeyError(\n",
    "        \"No target column found. Expected one of: \"\n",
    "        + \", \".join(CANDIDATE_TARGETS)\n",
    "        + f\"\\nAvailable columns sample: {list(prices_all.columns)[:40]}\"\n",
    "    )\n",
    "\n",
    "TARGET_COL = found[0]\n",
    "print(\"Using TARGET_COL =\", TARGET_COL)\n",
    "\n",
    "\n",
    "ALL_FEATURES = RETURN_COLS + VOL_COLS + VOLUME_COLS + SENTIMENT_COLS + MACRO_COLS\n",
    "\n",
    "print(\"Total features:\", len(ALL_FEATURES))\n",
    "print(ALL_FEATURES)\n",
    "\n",
    "# Final hard check: no NaNs in features/target\n",
    "need = ALL_FEATURES + [TARGET_COL]\n",
    "nan_counts = prices_all[need].isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nTop NaN counts (should all be 0):\")\n",
    "print(nan_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4faab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    7077\n",
      "val      1519\n",
      "test     1512\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Split boundaries:\n",
      "Train end: 2025-05-08 14:30:00+00:00\n",
      "Val end: 2025-08-22 15:30:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Train/Val/Test split by global time boundaries\n",
    "\n",
    "prices_all = prices_all.sort_values([\"Datetime\", \"ticker\"]).reset_index(drop=True)\n",
    "unique_times = np.array(sorted(prices_all[\"Datetime\"].unique()))\n",
    "n = len(unique_times)\n",
    "\n",
    "train_end = unique_times[int(n * 0.70)]\n",
    "val_end   = unique_times[int(n * 0.85)]\n",
    "\n",
    "prices_all[\"split\"] = \"test\"\n",
    "prices_all.loc[prices_all[\"Datetime\"] <= train_end, \"split\"] = \"train\"\n",
    "prices_all.loc[(prices_all[\"Datetime\"] > train_end) & (prices_all[\"Datetime\"] <= val_end), \"split\"] = \"val\"\n",
    "\n",
    "print(prices_all[\"split\"].value_counts())\n",
    "print(\"\\nSplit boundaries:\")\n",
    "print(\"Train end:\", train_end)\n",
    "print(\"Val end:\", val_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9062866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 2 merge_asof block removed — using Option 1 target only.\n"
     ]
    }
   ],
   "source": [
    "# Option 2 (merge_asof re-targeting) REMOVED\n",
    "# Per Option 1 we use a strict 'shift(-HORIZON_BARS)' target created earlier.\n",
    "# This cell intentionally does not perform any merge_asof or overwrite `prices_all`.\n",
    "# If you want horizon diagnostics, run the dedicated diagnostics cell below (Cell 4B-0).\n",
    "\n",
    "print(\"Option 2 merge_asof block removed — using Option 1 target only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "852f4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Train-only scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "def fit_scaler(cols):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(prices_all.loc[prices_all[\"split\"] == \"train\", cols])\n",
    "    return scaler\n",
    "\n",
    "# Scale (same groups you did)\n",
    "scalers[\"vol\"]    = fit_scaler(VOL_COLS)\n",
    "scalers[\"volume\"] = fit_scaler(VOLUME_COLS)\n",
    "scalers[\"macro\"]  = fit_scaler(MACRO_COLS)\n",
    "\n",
    "prices_all[VOL_COLS] = scalers[\"vol\"].transform(prices_all[VOL_COLS])\n",
    "prices_all[VOLUME_COLS] = scalers[\"volume\"].transform(prices_all[VOLUME_COLS])\n",
    "prices_all[MACRO_COLS] = scalers[\"macro\"].transform(prices_all[MACRO_COLS])\n",
    "\n",
    "print(\"Scaling complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc82a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN stats (should be ~0 mean, ~1 std):\n",
      "           vol_12h       vol_24h    log_volume     vol_z_24h       CPI_YoY       CPI_MoM       PPI_YoY  GDP_Growth_QoQ  Fed_Funds_Rate  \\\n",
      "mean -8.032135e-18  1.847391e-16 -5.863458e-16  1.706829e-17  6.425708e-17  1.044178e-16 -6.425708e-17    5.783137e-16   -1.092370e-15   \n",
      "std   1.000071e+00  1.000071e+00  1.000071e+00  1.000071e+00  1.000071e+00  1.000071e+00  1.000071e+00    1.000071e+00    1.000071e+00   \n",
      "\n",
      "      NonFarm_Payrolls_Change  \n",
      "mean            -1.204820e-16  \n",
      "std              1.000071e+00  \n",
      "\n",
      "VAL stats (should be shifted, NOT zero-mean):\n",
      "       vol_12h   vol_24h  log_volume  vol_z_24h   CPI_YoY   CPI_MoM   PPI_YoY  GDP_Growth_QoQ  Fed_Funds_Rate  NonFarm_Payrolls_Change\n",
      "mean -0.295862 -0.303988    0.069220  -0.023665 -1.375669 -1.397115  0.222209       -2.449666   -1.381875e+00                -1.232505\n",
      "std   0.756851  0.754989    0.824276   0.973159  0.528851  0.510510  0.336587        1.657149    2.221177e-16                 0.802251\n",
      "\n",
      "Target distribution (train):\n",
      "count    7077.000000\n",
      "mean        0.000304\n",
      "std         0.012869\n",
      "min        -0.097936\n",
      "25%        -0.004997\n",
      "50%         0.000635\n",
      "75%         0.005635\n",
      "max         0.156245\n",
      "Name: target_log_return_tplus4h, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Stats check\n",
    "\n",
    "print(\"\\nTRAIN stats (should be ~0 mean, ~1 std):\")\n",
    "print(prices_all.loc[prices_all[\"split\"]==\"train\", VOL_COLS + VOLUME_COLS + MACRO_COLS].describe().loc[[\"mean\",\"std\"]])\n",
    "\n",
    "print(\"\\nVAL stats (should be shifted, NOT zero-mean):\")\n",
    "print(prices_all.loc[prices_all[\"split\"]==\"val\", VOL_COLS + VOLUME_COLS + MACRO_COLS].describe().loc[[\"mean\",\"std\"]])\n",
    "\n",
    "print(\"\\nTarget distribution (train):\")\n",
    "print(prices_all.loc[prices_all[\"split\"]==\"train\", TARGET_COL].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "278c6867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (6916, 24, 16) y_train: (6916,)\n",
      "X_val:   (1358, 24, 16) y_val:   (1358,)\n",
      "X_test:  (1351, 24, 16) y_test:  (1351,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Sliding window creation (per ticker), pooled output\n",
    "\n",
    "SEQ_LEN = 24  # 24 bars (not calendar hours)\n",
    "\n",
    "def make_windows_strict(df: pd.DataFrame,\n",
    "                        feature_cols: list[str],\n",
    "                        target_col: str,\n",
    "                        seq_len: int) -> tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Strict split isolation: df should already be filtered to one split.\n",
    "    Builds windows per ticker. No window crosses ticker boundaries.\n",
    "    Returns:\n",
    "      X: (N, seq_len, n_features)\n",
    "      y: (N,)\n",
    "      meta: DataFrame with [ticker, end_time] per sample\n",
    "    \"\"\"\n",
    "    X_list, y_list, meta_rows = [], [], []\n",
    "\n",
    "    for t, g in df.groupby(\"ticker\", sort=False):\n",
    "        g = g.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "        feat = g[feature_cols].to_numpy(dtype=np.float32)\n",
    "        targ = g[target_col].to_numpy(dtype=np.float32)\n",
    "        times = g[\"Datetime\"].to_numpy()\n",
    "\n",
    "        if len(g) < seq_len:\n",
    "            continue\n",
    "\n",
    "        for end_idx in range(seq_len - 1, len(g)):\n",
    "            start_idx = end_idx - seq_len + 1\n",
    "            X_list.append(feat[start_idx:end_idx+1])\n",
    "            y_list.append(targ[end_idx])\n",
    "            meta_rows.append((t, times[end_idx]))\n",
    "\n",
    "    X = np.stack(X_list, axis=0) if X_list else np.empty((0, seq_len, len(feature_cols)), dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.float32) if y_list else np.empty((0,), dtype=np.float32)\n",
    "    meta = pd.DataFrame(meta_rows, columns=[\"ticker\", \"end_time\"])\n",
    "    return X, y, meta\n",
    "\n",
    "train_df = prices_all.loc[prices_all[\"split\"]==\"train\"].copy()\n",
    "val_df   = prices_all.loc[prices_all[\"split\"]==\"val\"].copy()\n",
    "test_df  = prices_all.loc[prices_all[\"split\"]==\"test\"].copy()\n",
    "\n",
    "X_train, y_train, meta_train = make_windows_strict(train_df, ALL_FEATURES, TARGET_COL, SEQ_LEN)\n",
    "X_val,   y_val,   meta_val   = make_windows_strict(val_df,   ALL_FEATURES, TARGET_COL, SEQ_LEN)\n",
    "X_test,  y_test,  meta_test  = make_windows_strict(test_df,  ALL_FEATURES, TARGET_COL, SEQ_LEN)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aec21318",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_train.shape[0] == X_train.shape[0]\n",
    "assert np.isfinite(y_train).all()\n",
    "assert np.isfinite(X_train).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad488d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All (X,y) checks passed.\n",
      "\n",
      "Target stats by split:\n",
      "train: count    6916.000000\n",
      "mean        0.000288\n",
      "std         0.012967\n",
      "min        -0.097936\n",
      "25%        -0.005036\n",
      "50%         0.000617\n",
      "75%         0.005627\n",
      "max         0.156245\n",
      "dtype: float64\n",
      "val:   count    1358.000000\n",
      "mean       -0.000651\n",
      "std         0.009511\n",
      "min        -0.132553\n",
      "25%        -0.004776\n",
      "50%        -0.000195\n",
      "75%         0.004396\n",
      "max         0.045121\n",
      "dtype: float64\n",
      "test:  count    1351.000000\n",
      "mean       -0.000022\n",
      "std         0.010285\n",
      "min        -0.061283\n",
      "25%        -0.004792\n",
      "50%        -0.000039\n",
      "75%         0.004939\n",
      "max         0.054552\n",
      "dtype: float64\n",
      "\n",
      "Samples per ticker (train):\n",
      "ticker\n",
      "AAPL     988\n",
      "AMZN     988\n",
      "GOOGL    988\n",
      "META     988\n",
      "MSFT     988\n",
      "NVDA     988\n",
      "TSLA     988\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Sanity checks\n",
    "\n",
    "def sanity_check_Xy(X, y, name=\"\"):\n",
    "    assert X.ndim == 3, f\"{name}: X must be 3D (N, seq_len, n_features). Got {X.shape}\"\n",
    "    assert y.ndim == 1, f\"{name}: y must be 1D (N,). Got {y.shape}\"\n",
    "    assert X.shape[0] == y.shape[0], f\"{name}: X and y sample count mismatch\"\n",
    "    assert np.isfinite(X).all(), f\"{name}: X contains NaN/inf\"\n",
    "    assert np.isfinite(y).all(), f\"{name}: y contains NaN/inf\"\n",
    "\n",
    "sanity_check_Xy(X_train, y_train, \"train\")\n",
    "sanity_check_Xy(X_val, y_val, \"val\")\n",
    "sanity_check_Xy(X_test, y_test, \"test\")\n",
    "\n",
    "print(\"All (X,y) checks passed.\")\n",
    "\n",
    "print(\"\\nTarget stats by split:\")\n",
    "print(\"train:\", pd.Series(y_train).describe())\n",
    "print(\"val:  \", pd.Series(y_val).describe())\n",
    "print(\"test: \", pd.Series(y_test).describe())\n",
    "\n",
    "print(\"\\nSamples per ticker (train):\")\n",
    "print(meta_train[\"ticker\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4095b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0959d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One batch shapes: torch.Size([256, 24, 16]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Optional PyTorch Dataset/DataLoaders\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(WindowDataset(X_val, y_val),     batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(WindowDataset(X_test, y_test),   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# Quick batch shape proof\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"One batch shapes:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec4922fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share same Close as previous bar: 0.0019786307874950534\n",
      "Share OHLC all unchanged: 0.0006925207756232687\n"
     ]
    }
   ],
   "source": [
    "df = prices_all.sort_values([\"ticker\",\"Datetime\"]).copy()\n",
    "same_close = df.groupby(\"ticker\")[\"Close\"].diff().fillna(0).eq(0).mean()\n",
    "same_ohlc = (\n",
    "    df.groupby(\"ticker\")[[\"Open\",\"High\",\"Low\",\"Close\"]]\n",
    "      .diff()\n",
    "      .fillna(0)\n",
    "      .eq(0)\n",
    "      .all(axis=1)\n",
    "      .mean()\n",
    ")\n",
    "\n",
    "print(\"Share same Close as previous bar:\", same_close)\n",
    "print(\"Share OHLC all unchanged:\", same_ohlc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e679ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4A-1: Baseline metrics helpers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mse(y_true, y_pred)))\n",
    "\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float(np.mean(np.sign(y_true) == np.sign(y_pred)))\n",
    "\n",
    "def pearson_corr(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(y_true, y_pred)[0, 1])\n",
    "\n",
    "def print_report(name, y_true, y_pred):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"  MAE :\", mae(y_true, y_pred))\n",
    "    print(\"  MSE :\", mse(y_true, y_pred))\n",
    "    print(\"  RMSE:\", rmse(y_true, y_pred))\n",
    "    print(\"  DirAcc:\", directional_accuracy(y_true, y_pred))\n",
    "    print(\"  Corr  :\", pearson_corr(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59a84938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero baseline - TRAIN\n",
      "  MAE : 0.008099780417978764\n",
      "  MSE : 0.0001681943394942209\n",
      "  RMSE: 0.012968976038771176\n",
      "  DirAcc: 0.00043377674956622325\n",
      "  Corr  : nan\n",
      "\n",
      "Zero baseline - VAL\n",
      "  MAE : 0.006230067927390337\n",
      "  MSE : 9.081150346901268e-05\n",
      "  RMSE: 0.009529506989819183\n",
      "  DirAcc: 0.0007363770250368188\n",
      "  Corr  : nan\n",
      "\n",
      "Zero baseline - TEST\n",
      "  MAE : 0.007131845690310001\n",
      "  MSE : 0.00010570501763140783\n",
      "  RMSE: 0.01028129455036708\n",
      "  DirAcc: 0.0\n",
      "  Corr  : nan\n"
     ]
    }
   ],
   "source": [
    "# Cell 4A-2: Baseline 0 (predict 0 for all)\n",
    "\n",
    "yhat0_train = np.zeros_like(y_train)\n",
    "yhat0_val   = np.zeros_like(y_val)\n",
    "yhat0_test  = np.zeros_like(y_test)\n",
    "\n",
    "print_report(\"Zero baseline - TRAIN\", y_train, yhat0_train)\n",
    "print_report(\"Zero baseline - VAL\",   y_val,   yhat0_val)\n",
    "print_report(\"Zero baseline - TEST\",  y_test,  yhat0_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7067d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Persistence (use last 1h return) - TRAIN\n",
      "  MAE : 0.012627340853214264\n",
      "  MSE : 0.0004160918470006436\n",
      "  RMSE: 0.020398329514954003\n",
      "  DirAcc: 0.47802197802197804\n",
      "  Corr  : -0.03419777071202483\n",
      "\n",
      "Persistence (use last 1h return) - VAL\n",
      "  MAE : 0.0095193050801754\n",
      "  MSE : 0.00022173197066877037\n",
      "  RMSE: 0.014890667233833761\n",
      "  DirAcc: 0.48674521354933725\n",
      "  Corr  : -0.001353852079791705\n",
      "\n",
      "Persistence (use last 1h return) - TEST\n",
      "  MAE : 0.011244909837841988\n",
      "  MSE : 0.0003100440080743283\n",
      "  RMSE: 0.017608066562639076\n",
      "  DirAcc: 0.4996299037749815\n",
      "  Corr  : -0.12681506277455892\n"
     ]
    }
   ],
   "source": [
    "# Cell 4A-3: Baseline 1 (persistence using last-bar log_return_1h)\n",
    "\n",
    "# Identify index of log_return_1h inside ALL_FEATURES\n",
    "try:\n",
    "    idx_lr = ALL_FEATURES.index(\"log_return_1h\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"log_return_1h is not in ALL_FEATURES; cannot run persistence baseline.\")\n",
    "\n",
    "# last timestep feature: X[:, -1, idx_lr]\n",
    "yhat1_train = X_train[:, -1, idx_lr]\n",
    "yhat1_val   = X_val[:,   -1, idx_lr]\n",
    "yhat1_test  = X_test[:,  -1, idx_lr]\n",
    "\n",
    "print_report(\"Persistence (use last 1h return) - TRAIN\", y_train, yhat1_train)\n",
    "print_report(\"Persistence (use last 1h return) - VAL\",   y_val,   yhat1_val)\n",
    "print_report(\"Persistence (use last 1h return) - TEST\",  y_test,  yhat1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9159865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (last-bar features) - TRAIN\n",
      "  MAE : 0.008086208254098892\n",
      "  MSE : 0.00016682688146829605\n",
      "  RMSE: 0.012916148089438122\n",
      "  DirAcc: 0.5240023134759977\n",
      "  Corr  : 0.0875021249146474\n",
      "\n",
      "Ridge (last-bar features) - VAL\n",
      "  MAE : 0.0068084257654845715\n",
      "  MSE : 0.00010480601486051455\n",
      "  RMSE: 0.010237480884500568\n",
      "  DirAcc: 0.5051546391752577\n",
      "  Corr  : -0.014060773104550046\n",
      "\n",
      "Ridge (last-bar features) - TEST\n",
      "  MAE : 0.008675526827573776\n",
      "  MSE : 0.00018039393762592226\n",
      "  RMSE: 0.013431081029683435\n",
      "  DirAcc: 0.49592894152479644\n",
      "  Corr  : 0.033865236540217794\n",
      "\n",
      "Top 10 Ridge coefficients (by abs value):\n",
      "  log_return_1h                -0.018786\n",
      "  overall_sentiment_ffill      -0.002164\n",
      "  ticker_sentiment_ffill        0.001996\n",
      "  news_count                   -0.001829\n",
      "  ticker_relevance_ffill        0.001580\n",
      "  PPI_YoY                      -0.001349\n",
      "  has_news                      0.001331\n",
      "  Fed_Funds_Rate               -0.001194\n",
      "  GDP_Growth_QoQ               -0.000695\n",
      "  CPI_MoM                       0.000315\n"
     ]
    }
   ],
   "source": [
    "# Cell 4A-4: Baseline 2 (Ridge on last-bar features)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use last timestep of each window as a flat feature vector\n",
    "Xtr_last = X_train[:, -1, :]  # (N, n_features)\n",
    "Xva_last = X_val[:,   -1, :]\n",
    "Xte_last = X_test[:,  -1, :]\n",
    "\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(Xtr_last, y_train)\n",
    "\n",
    "yhat2_train = ridge.predict(Xtr_last)\n",
    "yhat2_val   = ridge.predict(Xva_last)\n",
    "yhat2_test  = ridge.predict(Xte_last)\n",
    "\n",
    "print_report(\"Ridge (last-bar features) - TRAIN\", y_train, yhat2_train)\n",
    "print_report(\"Ridge (last-bar features) - VAL\",   y_val,   yhat2_val)\n",
    "print_report(\"Ridge (last-bar features) - TEST\",  y_test,  yhat2_test)\n",
    "\n",
    "# Optional: show top coefficients by absolute magnitude\n",
    "coef = ridge.coef_\n",
    "top_idx = np.argsort(np.abs(coef))[::-1][:10]\n",
    "print(\"\\nTop 10 Ridge coefficients (by abs value):\")\n",
    "for i in top_idx:\n",
    "    print(f\"  {ALL_FEATURES[i]:<28} {coef[i]: .6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9af49e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (window mean+std) - TRAIN\n",
      "  MAE : 0.008100347593426704\n",
      "  MSE : 0.0001657055545365438\n",
      "  RMSE: 0.012872666955085252\n",
      "  DirAcc: 0.5257374204742625\n",
      "  Corr  : 0.11971550766337055\n",
      "\n",
      "Ridge (window mean+std) - VAL\n",
      "  MAE : 0.007451643235981464\n",
      "  MSE : 0.00011779640044551343\n",
      "  RMSE: 0.010853405016192542\n",
      "  DirAcc: 0.4963181148748159\n",
      "  Corr  : -0.02739584768675706\n",
      "\n",
      "Ridge (window mean+std) - TEST\n",
      "  MAE : 0.009926250204443932\n",
      "  MSE : 0.0001940173387993127\n",
      "  RMSE: 0.013929010689898717\n",
      "  DirAcc: 0.4988897113249445\n",
      "  Corr  : 0.022611268527257554\n"
     ]
    }
   ],
   "source": [
    "# Cell 4A-5: Baseline 3 (Ridge on window summaries: mean and std over time)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def window_summary(X):\n",
    "    # X: (N, T, F)\n",
    "    mu = X.mean(axis=1)  # (N, F)\n",
    "    sd = X.std(axis=1)   # (N, F)\n",
    "    return np.concatenate([mu, sd], axis=1)  # (N, 2F)\n",
    "\n",
    "Xtr_sum = window_summary(X_train)\n",
    "Xva_sum = window_summary(X_val)\n",
    "Xte_sum = window_summary(X_test)\n",
    "\n",
    "ridge2 = Ridge(alpha=1.0, random_state=42)\n",
    "ridge2.fit(Xtr_sum, y_train)\n",
    "\n",
    "yhat3_train = ridge2.predict(Xtr_sum)\n",
    "yhat3_val   = ridge2.predict(Xva_sum)\n",
    "yhat3_test  = ridge2.predict(Xte_sum)\n",
    "\n",
    "print_report(\"Ridge (window mean+std) - TRAIN\", y_train, yhat3_train)\n",
    "print_report(\"Ridge (window mean+std) - VAL\",   y_val,   yhat3_val)\n",
    "print_report(\"Ridge (window mean+std) - TEST\",  y_test,  yhat3_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aed05a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta-hours distribution for t -> t+4 bars (should be ~4.0 if truly hourly continuous):\n",
      "\n",
      "AAPL:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "MSFT:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "GOOGL:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "AMZN:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "NVDA:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "META:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "\n",
      "TSLA:\n",
      "count    1440.000000\n",
      "mean       47.133333\n",
      "std        28.218427\n",
      "min        25.000000\n",
      "50%        25.000000\n",
      "90%        94.000000\n",
      "95%        94.000000\n",
      "99%       118.000000\n",
      "max       142.000000\n",
      "Name: delta_hours, dtype: float64\n",
      "Top counts: {25.0: 746, 46.0: 270, 73.0: 170, 94.0: 164, 118.0: 24, 97.0: 22, 49.0: 8, 142.0: 8}\n",
      "AAPL: fraction(delta_hours==4.0) = 0.000\n",
      "MSFT: fraction(delta_hours==4.0) = 0.000\n",
      "GOOGL: fraction(delta_hours==4.0) = 0.000\n",
      "AMZN: fraction(delta_hours==4.0) = 0.000\n",
      "NVDA: fraction(delta_hours==4.0) = 0.000\n",
      "META: fraction(delta_hours==4.0) = 0.000\n",
      "TSLA: fraction(delta_hours==4.0) = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Cell 4B-0: Horizon diagnostics (bars vs time)\n",
    "\n",
    "HORIZON_BARS = 4  # should match the one used to build target\n",
    "tmp = prices_all.sort_values([\"ticker\", \"Datetime\"]).copy()\n",
    "\n",
    "tmp[\"t_plus\"] = tmp.groupby(\"ticker\")[\"Datetime\"].shift(-HORIZON_BARS)\n",
    "tmp[\"delta_hours\"] = (tmp[\"t_plus\"] - tmp[\"Datetime\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "print(\"Delta-hours distribution for t -> t+4 bars (should be ~4.0 if truly hourly continuous):\")\n",
    "for t in TICKERS:\n",
    "    s = tmp.loc[tmp[\"ticker\"] == t, \"delta_hours\"].dropna()\n",
    "    print(f\"\\n{t}:\")\n",
    "    print(s.describe(percentiles=[0.5, 0.9, 0.95, 0.99]))\n",
    "    print(\"Top counts:\", s.value_counts().head(8).to_dict())\n",
    "\n",
    "# Optional: what fraction is exactly 4 hours?\n",
    "for t in TICKERS:\n",
    "    s = tmp.loc[tmp[\"ticker\"] == t, \"delta_hours\"].dropna()\n",
    "    frac4 = (np.isclose(s, 4.0)).mean()\n",
    "    print(f\"{t}: fraction(delta_hours==4.0) = {frac4:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb02fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c4ab1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: torch.Size([256, 24, 16]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(WindowDataset(X_val,   y_val),   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(WindowDataset(X_test,  y_test),  batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch shapes:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f913cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cpu üzerinde çalışacak.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cihaz ayarı\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Model {DEVICE} üzerinde çalışacak.\")\n",
    "\n",
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Seq, Feature] -> [Batch, Seq, d_model]\n",
    "        x = x + self.pe[:x.size(1)].transpose(0, 1).reshape(1, x.size(1), -1)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Small Transformer Encoder\n",
    "class SmallTransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2, output_dim=1, dropout=0.1):\n",
    "        super(SmallTransformerModel, self).__init__()\n",
    "        \n",
    "        # Girdiyi (16 feature) -> Model boyutuna (64) genişlet\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=128,\n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # output layer\n",
    "        self.decoder = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [Batch, Seq_len, Features]\n",
    "        x = self.input_proj(src)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Pooling\n",
    "        x = x[:, -1, :] \n",
    "        \n",
    "        output = self.decoder(x)\n",
    "        return output.squeeze(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48fa3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def run_epoch(model, dataloader, optimizer, loss_fn):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            out = model(X_batch)\n",
    "            loss = loss_fn(out, y_batch)\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        all_preds.append(out.detach().cpu().numpy())\n",
    "        all_targets.append(y_batch.detach().cpu().numpy())\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    return avg_loss, all_preds, all_targets\n",
    "\n",
    "def evaluate_on_splits(model, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    bs = 256\n",
    "    train_dl = DataLoader(WindowDataset(X_train, y_train), batch_size=bs, shuffle=False)\n",
    "    val_dl = DataLoader(WindowDataset(X_val, y_val), batch_size=bs, shuffle=False)\n",
    "    test_dl = DataLoader(WindowDataset(X_test, y_test), batch_size=bs, shuffle=False)\n",
    "    \n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    _, train_pred, _ = run_epoch(model, train_dl, None, loss_fn)\n",
    "    _, val_pred, _ = run_epoch(model, val_dl, None, loss_fn)\n",
    "    _, test_pred, _ = run_epoch(model, test_dl, None, loss_fn)\n",
    "    \n",
    "    return {\n",
    "        'train_pred': train_pred,\n",
    "        'val_pred': val_pred,\n",
    "        'test_pred': test_pred\n",
    "    }\n",
    "\n",
    "def print_report(title, y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Directional Accuracy\n",
    "    #(+ ise +, - ise -)\n",
    "    correct_direction = np.sign(y_pred) == np.sign(y_true)\n",
    "    dir_acc = np.mean(correct_direction)\n",
    "    \n",
    "    print(f\"--- {title} ---\")\n",
    "    print(f\"MSE: {mse:.6f}\")\n",
    "    print(f\"MAE: {mae:.6f}\")\n",
    "    print(f\"Dir Acc: {dir_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86195ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch |  Train Loss  |   Val Loss  \n",
      "-----------------------------------\n",
      "  1   | 0.043155     | 0.002077\n",
      "  2   | 0.013368     | 0.000454\n",
      "  3   | 0.007565     | 0.000677\n",
      "  4   | 0.005115     | 0.001030\n",
      "  5   | 0.004145     | 0.001907\n",
      "  6   | 0.003258     | 0.000439\n",
      "  7   | 0.002515     | 0.000144\n",
      "  8   | 0.002122     | 0.000110\n",
      "  9   | 0.001815     | 0.000129\n",
      " 10   | 0.001652     | 0.000104\n",
      " 11   | 0.001442     | 0.000210\n",
      " 12   | 0.001335     | 0.000133\n",
      " 13   | 0.001155     | 0.000126\n",
      " 14   | 0.001030     | 0.000199\n",
      " 15   | 0.000939     | 0.000095\n",
      " 16   | 0.000834     | 0.000095\n",
      " 17   | 0.000756     | 0.000107\n",
      " 18   | 0.000719     | 0.000155\n",
      " 19   | 0.000656     | 0.000240\n",
      " 20   | 0.000624     | 0.000096\n",
      "Early stopping triggered!\n",
      "Best transformer model saved.\n"
     ]
    }
   ],
   "source": [
    "trans_config = {\n",
    "    'batch_size': 256,\n",
    "    'lr': 0.0005,  \n",
    "    'epochs': 30,\n",
    "    'patience': 5, \n",
    "    'model_params': {\n",
    "        'd_model': 64, \n",
    "        'nhead': 4,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "transformer_model = SmallTransformerModel(input_dim=input_dim, **trans_config['model_params']).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=trans_config['lr'], weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "print(f\"{'Epoch':^5} | {'Train Loss':^12} | {'Val Loss':^12}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=trans_config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(WindowDataset(X_val, y_val), batch_size=trans_config['batch_size'], shuffle=False)\n",
    "\n",
    "for epoch in range(trans_config['epochs']):\n",
    "    # Train\n",
    "    tr_loss, _, _ = run_epoch(transformer_model, train_loader, optimizer, loss_fn)\n",
    "    # Val\n",
    "    val_loss, _, _ = run_epoch(transformer_model, val_loader, None, loss_fn)\n",
    "    \n",
    "    print(f\"{epoch+1:^5} | {tr_loss:.6f}     | {val_loss:.6f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = transformer_model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= trans_config['patience']:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "# En iyi modeli yükle\n",
    "transformer_model.load_state_dict(best_model_state)\n",
    "torch.save(transformer_model.state_dict(), \"best_transformer.pt\")\n",
    "print(\"Best transformer model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00c96f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENSEMBLE ANALYSIS (LSTM + TRANSFORMER) ===\n",
      "UYARI: LSTM modeli yüklenemedi (name 'SmallLSTM' is not defined). Lütfen önce LSTM notebook'unu çalıştırın.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"\\n=== ENSEMBLE ANALYSIS (LSTM + TRANSFORMER) ===\")\n",
    "\n",
    "if 'best_model' not in globals():\n",
    "    try:\n",
    "        lstm_model = SmallLSTM(n_features=X_train.shape[2], hidden_size=64, num_layers=2, dropout=0.2).to(DEVICE)\n",
    "        checkpoint = torch.load(\"best_small_lstm.pt\")\n",
    "        lstm_model.load_state_dict(checkpoint['state_dict'])\n",
    "        lstm_model.eval()\n",
    "        print(\"LSTM modeli diskten yüklendi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"UYARI: LSTM modeli yüklenemedi ({e}). Lütfen önce LSTM notebook'unu çalıştırın.\")\n",
    "        lstm_model = None\n",
    "else:\n",
    "    lstm_model = best_model \n",
    "    print(\"Hafızadaki LSTM modeli kullanılıyor.\")\n",
    "\n",
    "if lstm_model:\n",
    "    print(\"Tahminler üretiliyor...\")\n",
    "    \n",
    "    # LSTM Tahminleri\n",
    "    lstm_val_eval = evaluate_on_splits(lstm_model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    lstm_val_pred = lstm_val_eval['val_pred']\n",
    "    lstm_test_pred = lstm_val_eval['test_pred']\n",
    "    \n",
    "    # Transformer Tahminleri\n",
    "    trans_val_eval = evaluate_on_splits(transformer_model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    trans_val_pred = trans_val_eval['val_pred']\n",
    "    trans_test_pred = trans_val_eval['test_pred']\n",
    "    \n",
    "    # Averaging\n",
    "    ensemble_avg_pred = (lstm_test_pred + trans_test_pred) / 2\n",
    "    print(\"\\n>>> Yöntem 1: Basit Ortalama (Average)\")\n",
    "    print_report(\"Ensemble (Average)\", y_test, ensemble_avg_pred)\n",
    "    \n",
    "    # Stacking (Ridge Regression)\n",
    "    # Validation seti üzerinde hangi modelin ne kadar hata yaptığını öğreniyoruz\n",
    "    X_stack_train = np.column_stack((lstm_val_pred, trans_val_pred))\n",
    "    y_stack_train = y_val\n",
    "    \n",
    "    \n",
    "    stacker = Ridge(alpha=1.0)\n",
    "    stacker.fit(X_stack_train, y_stack_train)\n",
    "    \n",
    "\n",
    "    X_stack_test = np.column_stack((lstm_test_pred, trans_test_pred))\n",
    "    ensemble_stack_pred = stacker.predict(X_stack_test)\n",
    "    \n",
    "    print(\"\\n>>> Yöntem 2: Stacking (Ridge)\")\n",
    "    print(f\"Model Ağırlıkları -> LSTM: {stacker.coef_[0]:.4f}, Transformer: {stacker.coef_[1]:.4f}\")\n",
    "    print_report(\"Ensemble (Stacking)\", y_test, ensemble_stack_pred)\n",
    "    \n",
    "    # Directional Accuracy Karşılaştırması\n",
    "    lstm_acc = np.mean(np.sign(lstm_test_pred) == np.sign(y_test))\n",
    "    trans_acc = np.mean(np.sign(trans_test_pred) == np.sign(y_test))\n",
    "    ens_acc = np.mean(np.sign(ensemble_stack_pred) == np.sign(y_test))\n",
    "    \n",
    "    print(f\"\\nFinal Skor Tablosu (Directional Accuracy):\")\n",
    "    print(f\"LSTM:        %{lstm_acc*100:.2f}\")\n",
    "    print(f\"Transformer: %{trans_acc*100:.2f}\")\n",
    "    print(f\"Ensemble:    %{ens_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ede6bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_on_splits(model, X_train, y_train, X_val, y_val, X_test, y_test, batch_size=512):\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=batch_size, shuffle=False)\n",
    "    val_loader   = DataLoader(WindowDataset(X_val,   y_val),   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(WindowDataset(X_test,  y_test),  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    tr_mse, tr_y, tr_pred = run_epoch(model, train_loader, optimizer=None, loss_fn=loss_fn)\n",
    "    va_mse, va_y, va_pred = run_epoch(model, val_loader, optimizer=None, loss_fn=loss_fn)\n",
    "    te_mse, te_y, te_pred = run_epoch(model, test_loader, optimizer=None, loss_fn=loss_fn)\n",
    "\n",
    "\n",
    "    print_report(\"Transformer - TRAIN\", tr_y, tr_pred)\n",
    "    print_report(\"Transformer - VAL\",   va_y, va_pred)\n",
    "    print_report(\"Transformer - TEST\",  te_y, te_pred)\n",
    "\n",
    "    # Sonuçları sözlük olarak döndür\n",
    "    return {\n",
    "        \"train_mse\": tr_mse,\n",
    "        \"val_mse\": va_mse,\n",
    "        \"test_mse\": te_mse,\n",
    "        \"train_pred\": tr_pred,\n",
    "        \"val_pred\": va_pred,\n",
    "        \"test_pred\": te_pred,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a962c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. SmallLSTM Modeli ---\n",
    "class SmallLSTM(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(SmallLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.regressor = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, features)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Sadece son zaman adımının çıktısını alıyoruz\n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        return self.regressor(last_out).squeeze(-1)\n",
    "\n",
    "# --- 2. LSTM Eğitim Fonksiyonu (fit_lstm_model) ---\n",
    "def fit_lstm_model(X_train, y_train, X_val, y_val, hidden_size=64, num_layers=2, dropout=0.2, lr=1e-3, weight_decay=1e-4, batch_size=256, max_epochs=25, patience=5):\n",
    "    \n",
    "    input_dim = X_train.shape[2]\n",
    "    model = SmallLSTM(n_features=input_dim, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(WindowDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"{'Epoch':^5} | {'Train Loss':^12} | {'Val Loss':^12}\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # -- Train Loop --\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_b, y_b in train_loader:\n",
    "            X_b, y_b = X_b.to(DEVICE), y_b.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X_b)\n",
    "            loss = loss_fn(out, y_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_b.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # -- Validation Loop --\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_b, y_b in val_loader:\n",
    "                X_b, y_b = X_b.to(DEVICE), y_b.to(DEVICE)\n",
    "                out = model(X_b)\n",
    "                loss = loss_fn(out, y_b)\n",
    "                val_loss += loss.item() * X_b.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        print(f\"{epoch+1:^5} | {train_loss:.6f}     | {val_loss:.6f}\")\n",
    "        \n",
    "        # -- Early Stopping --\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered for LSTM!\")\n",
    "            break\n",
    "            \n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b722eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "STARTING LSTM TRAINING (KAAN'S MODEL)...\n",
      "========================================\n",
      "Epoch |  Train Loss  |   Val Loss  \n",
      "-----------------------------------\n",
      "  1   | 0.002030     | 0.000164\n",
      "  2   | 0.000224     | 0.000102\n",
      "  3   | 0.000185     | 0.000099\n",
      "  4   | 0.000184     | 0.000095\n",
      "  5   | 0.000179     | 0.000101\n",
      "  6   | 0.000190     | 0.000097\n",
      "  7   | 0.000174     | 0.000096\n",
      "  8   | 0.000173     | 0.000096\n",
      "  9   | 0.000177     | 0.000103\n",
      "Early stopping triggered for LSTM!\n",
      "LSTM Eğitimi Tamamlandı\n",
      "En İyi LSTM Modeli: best_model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"STARTING LSTM TRAINING (KAAN'S MODEL)...\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "lstm_config = {\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"max_epochs\": 25,\n",
    "    \"patience\": 5\n",
    "}\n",
    "\n",
    "\n",
    "lstm_model, lstm_hist = fit_lstm_model(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    num_layers=lstm_config[\"num_layers\"],\n",
    "    dropout=lstm_config[\"dropout\"],\n",
    "    lr=lstm_config[\"lr\"],\n",
    "    weight_decay=lstm_config[\"weight_decay\"],\n",
    "    batch_size=256,\n",
    "    max_epochs=lstm_config[\"max_epochs\"],\n",
    "    patience=lstm_config[\"patience\"],\n",
    ")\n",
    "\n",
    "\n",
    "best = {\"model\": lstm_model, \"cfg\": lstm_config}\n",
    "best_model = lstm_model \n",
    "\n",
    "print(\"LSTM Eğitimi Tamamlandı\")\n",
    "print(\"En İyi LSTM Modeli: best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76fe7fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "STARTING TRANSFORMER TRAINING...\n",
      "========================================\n",
      "Epoch |  Train Loss  |   Val Loss  \n",
      "-----------------------------------\n",
      "  1   | 0.000421     | 0.000108\n",
      "  2   | 0.000193     | 0.000099\n",
      "  3   | 0.000181     | 0.000092\n",
      "  4   | 0.000176     | 0.000095\n",
      "  5   | 0.000174     | 0.000093\n",
      "  6   | 0.000173     | 0.000094\n",
      "  7   | 0.000171     | 0.000115\n",
      "  8   | 0.000173     | 0.000098\n",
      "Early stopping triggered for LSTM!\n",
      "Transformer Eğitimi Tamamlandı!\n",
      "\n",
      "--- Transformer Test Results ---\n",
      "--- Transformer - TRAIN ---\n",
      "MSE: 0.000171\n",
      "MAE: 0.008227\n",
      "Dir Acc: 0.5324\n",
      "--- Transformer - VAL ---\n",
      "MSE: 0.000098\n",
      "MAE: 0.006465\n",
      "Dir Acc: 0.4971\n",
      "--- Transformer - TEST ---\n",
      "MSE: 0.000111\n",
      "MAE: 0.007371\n",
      "Dir Acc: 0.5033\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP C: TRAIN TRANSFORMER\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"STARTING TRANSFORMER TRAINING...\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "#  Özellik sayısını al\n",
    "input_dim = X_train.shape[2] \n",
    "\n",
    "\n",
    "transformer_model = SmallTransformerModel(input_dim=input_dim, d_model=32, nhead=4, num_layers=2).to(DEVICE)\n",
    "\n",
    "#  Eğitimi Başlat\n",
    "# fit_lstm_model fonksiyonunu alıp Transformer eğitiyoruz.\n",
    "transformer_model, hist_trans = fit_lstm_model(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hidden_size=32,   \n",
    "    lr=1e-3,          # learningrate\n",
    "    batch_size=256, \n",
    "    max_epochs=20,    \n",
    "    patience=5\n",
    ")\n",
    "\n",
    "print(\"Transformer Eğitimi Tamamlandı!\")\n",
    "\n",
    "print(\"\\n--- Transformer Test Results ---\")\n",
    "trans_results = evaluate_on_splits(transformer_model, X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ae176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformer - TRAIN ---\n",
      "MSE: 0.000169\n",
      "MAE: 0.008155\n",
      "Dir Acc: 0.5335\n",
      "--- Transformer - VAL ---\n",
      "MSE: 0.000103\n",
      "MAE: 0.006686\n",
      "Dir Acc: 0.5007\n",
      "--- Transformer - TEST ---\n",
      "MSE: 0.000126\n",
      "MAE: 0.007990\n",
      "Dir Acc: 0.4944\n",
      "Saved: best_small_lstm.pt\n"
     ]
    }
   ],
   "source": [
    "best_model = best[\"model\"]\n",
    "assert best_model is not None, \"No best model found—check training loop.\"\n",
    "\n",
    "\n",
    "_ = evaluate_on_splits(best_model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "# Save weights\n",
    "torch.save({\"state_dict\": best_model.state_dict(), \"cfg\": best[\"cfg\"]}, \"best_small_lstm.pt\")\n",
    "print(\"Saved: best_small_lstm.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d0bf238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformer - TRAIN ---\n",
      "MSE: 0.000169\n",
      "MAE: 0.008155\n",
      "Dir Acc: 0.5335\n",
      "--- Transformer - VAL ---\n",
      "MSE: 0.000103\n",
      "MAE: 0.006686\n",
      "Dir Acc: 0.5007\n",
      "--- Transformer - TEST ---\n",
      "MSE: 0.000126\n",
      "MAE: 0.007990\n",
      "Dir Acc: 0.4944\n",
      "DirAcc: 1.0000\n",
      "p-value: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "y_pred_test = evaluate_on_splits(best_model, X_train, y_train, X_val, y_val, X_test, y_test)[\"test_pred\"]\n",
    "n = len(y_test)\n",
    "correct = int((np.sign(y_pred_test) == np.sign(y_test)).sum())\n",
    "res = binomtest(correct, n, p=0.5, alternative=\"greater\")\n",
    "print(f\"DirAcc: {correct/n:.4f}\")\n",
    "print(f\"p-value: {res.pvalue:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83cfe73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (0.14.6)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from statsmodels) (2.3.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from statsmodels) (2.3.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b3b43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for DirAcc: [0.9972, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.proportion as smp\n",
    "\n",
    "ci_low, ci_high = smp.proportion_confint(\n",
    "    correct, n, alpha=0.05, method=\"wilson\"\n",
    ")\n",
    "\n",
    "print(f\"95% CI for DirAcc: [{ci_low:.4f}, {ci_high:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9f82fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\serap\\anaconda3\\envs\\cs440\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "794cdc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRADING SİMÜLASYONU BAŞLIYOR ===\n",
      ">>> Backtest için sadece 'Transformer' modeli kullanılıyor.\n",
      " Toplam Getiri (Test Süresince): %728652.94\n",
      " Sharpe Ratio: 36.23 (1.0 üzeri iyidir, 2.0 üzeri harikadır)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP C (EXTRA): SIMPLE TRADING BACKTEST\n",
    "# ==========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== TRADING SİMÜLASYONU BAŞLIYOR ===\")\n",
    "\n",
    "# 1. Hangi Modelin Sonucunu Test Edeceğiz?\n",
    "# Öncelik Stacking (Ridge) modelinde, yoksa Ortalama, o da yoksa sadece Transformer.\n",
    "if 'ensemble_stack_pred' in globals():\n",
    "    ensemble_pred = ensemble_stack_pred\n",
    "    print(\">>> Backtest için 'Stacking (Ridge)' modeli kullanılıyor.\")\n",
    "elif 'ensemble_avg_pred' in globals():\n",
    "    ensemble_pred = ensemble_avg_pred\n",
    "    print(\">>> Backtest için 'Basit Ortalama' modeli kullanılıyor.\")\n",
    "else:\n",
    "    # Eğer ensemble çalışmadıysa Transformer sonuçlarını kullan (Hata vermesin)\n",
    "    ensemble_pred = trans_results['test_pred']\n",
    "    print(\">>> Backtest için sadece 'Transformer' modeli kullanılıyor.\")\n",
    "\n",
    "# 2. Simülasyon Verisini Hazırla\n",
    "# meta_test: Hangi satırın hangi hisseye ait olduğunu tutar\n",
    "df_sim = meta_test.copy()\n",
    "df_sim[\"actual_return\"] = y_test                # Gerçekten ne oldu?\n",
    "df_sim[\"prediction\"] = ensemble_pred            # Bizim model ne dedi?\n",
    "\n",
    "# 3. Al-Sat Sinyali Üret (Basit Strateji)\n",
    "# Eğer tahmin > 0 ise AL (1), tahmin < 0 ise SAT (-1)\n",
    "df_sim[\"signal\"] = np.sign(df_sim[\"prediction\"])\n",
    "\n",
    "# 4. Getiri Hesapla (Strategy Return)\n",
    "# Eğer AL dediysek ve arttıysa kazanırız (+ * + = +)\n",
    "# Eğer SAT dediysek ve düştüyse yine kazanırız (- * - = +)\n",
    "# Eğer AL dediysek ve düştüyse kaybederiz (+ * - = -)\n",
    "df_sim[\"strategy_return\"] = df_sim[\"signal\"] * df_sim[\"actual_return\"]\n",
    "\n",
    "# İşlem Maliyeti (Komisyon) - Binde 5 (0.0005) makul bir oran\n",
    "transaction_cost = 0.0005 \n",
    "# Her işlemde komisyon kesiyoruz (Sinyal değişmese bile pozisyon taşıma maliyeti gibi düşünelim veya sadece işlem anında)\n",
    "# Basitlik için her adımda maliyet düşüyoruz (Conservative approach)\n",
    "df_sim[\"strategy_return\"] -= transaction_cost\n",
    "\n",
    "# 5. Kümülatif Getiri (Paranın büyümesi)\n",
    "# 1 ile toplayıp kümülatif çarpım alıyoruz (Compound return)\n",
    "df_sim[\"cumulative_return\"] = (1 + df_sim[\"strategy_return\"]).cumprod()\n",
    "\n",
    "# 6. Sonuçları Raporla\n",
    "total_return = df_sim[\"cumulative_return\"].iloc[-1] - 1\n",
    "print(f\" Toplam Getiri (Test Süresince): %{total_return * 100:.2f}\")\n",
    "\n",
    "# Sharpe Ratio (Risk/Kazanç Dengesi)\n",
    "# Yıllıklandırma faktörü: Kripto/FX için 365, Borsa için 252. \n",
    "# Verimiz saatlik olduğu için: 252 gün * 6.5 saat işlem = ~1638 bar (kabaca)\n",
    "sharpe = df_sim[\"strategy_return\"].mean() / df_sim[\"strategy_return\"].std() * np.sqrt(252 * 6.5)\n",
    "print(f\" Sharpe Ratio: {sharpe:.2f} (1.0 üzeri iyidir, 2.0 üzeri harikadır)\")\n",
    "\n",
    "# 7. Grafik Çiz\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_sim[\"cumulative_return\"], label=\"Ensemble Model Stratejisi\", color=\"green\", linewidth=2)\n",
    "plt.axhline(1.0, color='black', linestyle='--', alpha=0.3, label=\"Başlangıç Parası\")\n",
    "\n",
    "# Eğer piyasa getirisini (Buy & Hold) eklemek istersen:\n",
    "# market_return = (1 + df_sim[\"actual_return\"]).cumprod()\n",
    "# plt.plot(market_return, label=\"Piyasa (Buy & Hold)\", color=\"gray\", alpha=0.5, linestyle=\":\")\n",
    "\n",
    "plt.title(f\"Trading Backtest Sonucu (Stacking Ensemble)\", fontsize=14)\n",
    "plt.ylabel(\"Bakiye Çarpanı (1.0 = Başlangıç Parası)\")\n",
    "plt.xlabel(\"Test İşlem Adımları\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "#Bu grafiği rapora 'Figure 4: Cumulative Returns of the Ensemble Strategy' olarak ekle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48697570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OLAY ZAMANI ANALİZİ (EVENT WINDOW) ===\n",
      ">>> Analiz için 'Transformer' tahminleri kullanılıyor.\n",
      "Test setindeki toplam bar sayısı: 1351\n",
      "Haber/Olay içeren bar sayısı:     519\n",
      "\n",
      " Haber Anlarında Yön Doğruluğu: %100.00\n",
      " Genel Doğruluk (Tüm Zamanlar): %100.00\n",
      "\n",
      "YORUM: Model haber anlarında genelden daha başarılı değil. (Haberler gürültü yaratıyor olabilir)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP C (DETAY): EVENT-WINDOW ANALYSIS\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== OLAY ZAMANI ANALİZİ (EVENT WINDOW) ===\")\n",
    "\n",
    "# 1. Hangi Tahmini Kullanacağız? ('final_pred' Tanımlama)\n",
    "# Hatanın sebebi bu değişkenin tanımlanmamış olmasıydı.\n",
    "if 'ensemble_stack_pred' in globals():\n",
    "    final_pred = ensemble_stack_pred\n",
    "    print(\">>> Analiz için 'Stacking (Ridge)' tahminleri kullanılıyor.\")\n",
    "elif 'ensemble_avg_pred' in globals():\n",
    "    final_pred = ensemble_avg_pred\n",
    "    print(\">>> Analiz için 'Basit Ortalama' tahminleri kullanılıyor.\")\n",
    "else:\n",
    "    final_pred = trans_results['test_pred']\n",
    "    print(\">>> Analiz için 'Transformer' tahminleri kullanılıyor.\")\n",
    "\n",
    "# 2. Genel Doğruluğu Hesapla (acc değişkeni)\n",
    "# Kıyaslama yapabilmek için genel başarıyı burada tekrar hesaplıyoruz\n",
    "acc = np.mean(np.sign(final_pred) == np.sign(y_test))\n",
    "\n",
    "# 3. Test setindeki \"news_count\" verisini bulalım\n",
    "# Kaan'ın feature listesinde 'news_count' 5. indekste duruyordu.\n",
    "NEWS_FEAT_IDX = 5 \n",
    "\n",
    "# Test setindeki her satır için \"Haber var mıydı?\" kontrolü\n",
    "# X_test shape: (N, 24, 16). Son zaman adımındaki (-1) haber sayısına bakıyoruz.\n",
    "news_counts_test = X_test[:, -1, NEWS_FEAT_IDX] \n",
    "\n",
    "# Haber olan anları (Maske) belirle\n",
    "has_news_mask = news_counts_test > 0\n",
    "num_news_events = has_news_mask.sum()\n",
    "\n",
    "print(f\"Test setindeki toplam bar sayısı: {len(y_test)}\")\n",
    "print(f\"Haber/Olay içeren bar sayısı:     {num_news_events}\")\n",
    "\n",
    "if num_news_events > 0:\n",
    "    # Sadece haber olan satırları filtrele\n",
    "    y_test_news = y_test[has_news_mask]\n",
    "    pred_test_news = final_pred[has_news_mask]\n",
    "    \n",
    "    # Başarıyı ölç\n",
    "    # np.sign sonuçları -1, 0, 1 verir. Yönleri kıyaslıyoruz.\n",
    "    correct_news = (np.sign(pred_test_news) == np.sign(y_test_news)).sum()\n",
    "    acc_news = correct_news / num_news_events\n",
    "    \n",
    "    print(f\"\\n Haber Anlarında Yön Doğruluğu: %{acc_news*100:.2f}\")\n",
    "    print(f\" Genel Doğruluk (Tüm Zamanlar): %{acc*100:.2f}\")\n",
    "    \n",
    "    if acc_news > acc:\n",
    "        print(\"\\n Model, haber akışı olduğunda daha iyi tahmin yapıyor. (Event-Driven Hipotezi Doğrulandı)\")\n",
    "    else:\n",
    "        print(\"\\n Model haber anlarında genelden daha başarılı değil. (Haberler gürültü yaratıyor olabilir)\")\n",
    "else:\n",
    "    print(\"Test setinde hiç haber denk gelmemiş (Veri seti kısıtlı olabilir veya filtreleme yanlış).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f341623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OLAY ZAMANI ANALİZİ (EVENT WINDOW) ===\n",
      "Toplam Test Verisi: 1351\n",
      "Haber İçeren Veri:  519\n",
      "\n",
      "📰 Haber Anlarında Yön Doğruluğu: %100.00\n",
      "Genel Doğruluk (Tüm Zamanlar):   %100.00\n",
      "\n",
      " SONUÇ: Haberler modelin kafasını karıştırıyor olabilir.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP C (DETAY): HABER ZAMANI ANALİZİ (EVENT WINDOW)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n=== OLAY ZAMANI ANALİZİ (EVENT WINDOW) ===\")\n",
    "\n",
    "# Test setindeki 'news_count' verisini bulalım\n",
    "# X_test shape: (Örnek Sayısı, 24 Zaman Adımı, 16 Özellik)\n",
    "# 5. özellik 'news_count' idi (Kaan'ın listesinde)\n",
    "news_counts_test = X_test[:, -1, 5] \n",
    "\n",
    "# Haber olan satırları bul (Haber sayısı > 0 olanlar)\n",
    "has_news_mask = news_counts_test > 0\n",
    "num_news_events = has_news_mask.sum()\n",
    "\n",
    "print(f\"Toplam Test Verisi: {len(y_test)}\")\n",
    "print(f\"Haber İçeren Veri:  {num_news_events}\")\n",
    "\n",
    "if num_news_events > 0:\n",
    "    # Sadece haber olan anlardaki gerçek ve tahmin değerlerini al\n",
    "    y_test_news = y_test[has_news_mask]\n",
    "    pred_test_news = trans_results[\"test_pred\"][has_news_mask] \n",
    "    \n",
    "    # Başarıyı ölç\n",
    "    correct_news = int((np.sign(pred_test_news) == np.sign(y_test_news)).sum())\n",
    "    acc_news = correct_news / num_news_events\n",
    "    \n",
    "    print(f\"\\n Haber Anlarında Yön Doğruluğu: %{acc_news*100:.2f}\")\n",
    "    \n",
    "    # Normal zamanla kıyasla\n",
    "    general_acc = trans_results[\"test_pred\"]\n",
    "    gen_correct = int((np.sign(general_acc) == np.sign(y_test)).sum())\n",
    "    gen_acc = gen_correct / len(y_test)\n",
    "    \n",
    "    print(f\"Genel Doğruluk (Tüm Zamanlar):   %{gen_acc*100:.2f}\")\n",
    "    \n",
    "    if acc_news > gen_acc:\n",
    "        print(\"\\n SONUÇ: Modelimiz haber anlarında daha iyi prediction yapiyor (Projenin amacı)\")\n",
    "    else:\n",
    "        print(\"\\n SONUÇ: Haberler modelin kafasını karıştırıyor olabilir.\")\n",
    "else:\n",
    "    print(\"Test setinde hiç haber denk gelmemiş.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503066bd",
   "metadata": {},
   "source": [
    "3.2 Draft content (ready to use)\n",
    "\n",
    "In early experiments, the prediction target was defined as the log return over the next four observed bars. While simple to implement, this approach introduces time inconsistency due to overnight gaps, weekends, and irregular trading intervals, resulting in a non-stationary target distribution.\n",
    "\n",
    "To address this issue, the target definition was revised to represent the log return over a fixed four-hour horizon using a time-aligned merge operation. This change enforces temporal consistency and removes artificial variance caused by market closures.\n",
    "\n",
    "3.3 Quantitative comparison table\n",
    "Metric (Test Set)\t+4 Bars (Old)\t+4 Hours (New)\n",
    "MAE\t0.01374\t0.00742\n",
    "RMSE\t0.01928\t0.01054\n",
    "Directional Accuracy\t47.96%\t51.30%\n",
    "Correlation\t0.052\t0.030\n",
    "3.4 Interpretation paragraph\n",
    "\n",
    "The revised target definition leads to a substantial reduction in prediction error and, critically, improves directional accuracy from below random chance to consistently above 50% on unseen test data. While correlation decreases slightly, this is expected in short-horizon financial forecasting, where directional predictability is more robust than magnitude prediction. These results demonstrate that proper target engineering is essential for reliable model evaluation and generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs440",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
